from __future__ import print_function,division
import random
import os
import torch
import pandas as pd
from skimage import io,transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset,DataLoader
import cv2
import warnings
from torchvision import transforms,utils


######################################################################
# The dataset we are going to deal with is that of facial pose.
# This means that a face is annotated like this:
#
# .. figure:: /_static/img/landmarked_face2.png
#    :width: 400
#
# Over all, 68 different landmark points are annotated for each face.
#
# .. note::
#     Download the dataset from `here <https://download.pytorch.org/tutorial/faces.zip>`_
#     so that the images are in a directory named 'faces/'.
#     This dataset was actually
#     generated by applying excellent `dlib's pose
#     estimation <http://blog.dlib.net/2014/08/real-time-face-pose-estimation.html>`__
#     on a few images from imagenet tagged as 'face'.
#
# Dataset comes with a csv file with annotations which looks like this:
#
# ::
#
#     image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y
#     0805personali01.jpg,27,83,27,98, ... 84,134
#     1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312
#
# Let's quickly read the CSV and get the annotations in an (N, 2) array where N
# is the number of landmarks.
#

######################################################################
# Let's write a simple helper function to show an image and its landmarks
# and use it to show a sample.
#

def show_landmarks(image,landmarks):
    """Show image with landmarks"""
    plt.imshow(image)
    plt.scatter(landmarks[:,0],landmarks[:,1],s=10,c='r',marker='.')
    plt.pause(0.01)
    
######################################################################
# Dataset class
# -------------
#
# ``torch.utils.data.Dataset`` is an abstract class representing a
# dataset.
# Your custom dataset should inherit ``Dataset`` and override the following
# methods:
#
# -  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.
# -  ``__getitem__`` to support the indexing such that ``dataset[i]`` can
#    be used to get :math:`i`\ th sample
#
# Let's create a dataset class for our face landmarks dataset. We will
# read the csv in ``__init__`` but leave the reading of images to
# ``__getitem__``. This is memory efficient because all the images are not
# stored in the memory at once but read as required.
#
# Sample of our dataset will be a dict
# ``{'source_image': source_image, 'target_image': target_image, 'landmarks': landmarks}``. Our datset will take an
# optional argument ``transform`` so that any required processing can be
# applied on the sample. We will see the usefulness of ``transform`` in the
# next section.
#

class FaceLandmarkDataset(Dataset):
    """Face Landmarks dataset"""
    def __init__(self,csv_file,root_dir,transform=None,rgb=True):
        """
        :param csv_file: Path to the csv file with annotation.
        :param root_dir: Dictionary of all images.
        :param transform: Optional transform to be applied on a sample.
        :param rgb:
        """
        self.landmark_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        print(len(self.landmark_frame))
        
        self.transform = transform
        self.rgb = rgb
        
    def __len__(self):
        return len(self.landmark_frame)
    
    def __getitem__(self, idx):
        source_img_path = self.landmark_frame.ix[idx,0]
        target_img_path = self.landmark_frame.ix[idx,1]
        source_image = cv2.imread(source_img_path)
        target_image = cv2.imread(target_img_path)
        if self.rgb:
            source_image = source_image[...,::-1]
            target_image = target_image[...,::-1]
        landmarks = self.landmark_frame.ix[idx,2:].as_matrix().astype('float')
        landmarks = landmarks.reshape(-1,2)
        sample = {'source_image':source_image,'target_image':target_image,'landmarks':landmarks}
        
        if self.transform:
            sample = self.transform(sample)
            
        return sample
    
######################################################################
# Let's instantiate this class and iterate through the data samples. We
# will print the sizes of first 4 samples and show their landmarks.
#


######################################################################
# Transforms
# ----------
#
# One issue we can see from the above is that the samples are not of the
# same size. Most neural networks expect the images of a fixed size.
# Therefore, we will need to write some prepocessing code.
# Let's create three transforms:
#
# -  ``Rescale``: to scale the image
# -  ``RandomCrop``: to crop from image randomly. This is data
#    augmentation.
# -  ``ToTensor``: to convert the numpy images to torch images (we need to
#    swap axes).
#
# We will write them as callable classes instead of simple functions so
# that parameters of the transform need not be passed everytime it's
# called. For this, we just need to implement ``__call__`` method and
# if required, ``__init__`` method. We can then use a transform like this:
#
# ::
#
#     tsfm = Transform(params)
#     transformed_sample = tsfm(sample)
#
# Observe below how these transforms had to be applied both on the image and
# landmarks.
#

class Rescale(object):
    """
    Rescale the image in the sample to a given size.
    """
    def __init__(self,output_size):
        """
        :param output_size: Type: tuple or int. If tuple, output is matched to output_size.
        If int, smaller of image edges is mtched to output_size keeping aspect ratio the same.
        """
        assert isinstance(output_size,(int,tuple))
        self.output_size = output_size
        
    def __call__(self,sample):
        source_image, target_image, landmarks = sample['source_image'], sample['target_image'],sample['landmarks']
        
        h,w = source_image.shape[:2]
        if isinstance(self.output_size,int):
            if h>w:
                new_h,new_w = self.output_size*h/w , self.output_size
            else:
                new_h,new_w = self.output_size,self.output_size*w/h
        else:
            new_h,new_w = self.output_size
            
        new_h , new_w = int(new_h),int(new_w)
        
        source_img = cv2.resize(source_image,(new_h,new_w))
        target_img = cv2.resize(target_image,(new_h,new_w))
        
        landmarks = landmarks * [new_w/w,new_h/h]
        
        return {'source_image':source_img,'target_image':target_img,'landmarks':landmarks}
    
class RandomCrop(object):
    """
    Crop randomly the image in a sample.
    """
    def __init__(self,output_size):
        """
        :param output_size: (tuple or int) Desired crop size, if int, square crop.
        """
        assert isinstance(output_size,(int,tuple))
        if isinstance(output_size,int):
            self.output_size = (output_size,output_size)
        else:
            assert len(output_size)==2
            self.output_size = output_size
            
    def __call__(self, sample):
        source_image,target_image,landmarks = sample['source_image'],sample['target_image'],sample['landmarks']
        h,w = source_image.shape[:2]
        new_h,new_w = self.output_size
        
        top = np.random.randint(0,h-new_h)
        left = np.random.randint(0,w-new_w)
        
        source_image = source_image[top:top+new_h,left:left+new_w]
        target_image = target_image[top:top+new_h,left:left+new_w]
        
        landmarks = landmarks - [left,top]
        return {'source_image':source_image,'target_image':target_image,'landmarks':landmarks}
    

        
        
        
